var searchIndex = {};
searchIndex["cv"] = {"doc":"This library primarily provides a binding and API for OpenCV 3.x.","items":[[3,"Mat","cv","This wraps OpenCV's `Mat` class which is designed for n-dimensional dense array. It's the most widely used data structure in image/video processing since images are often stored as `Mat`.",null,null],[12,"inner","","Pointer to the actual C/C++ data structure",0,null],[12,"cols","","Number of columns",0,null],[12,"rows","","Number of rows",0,null],[12,"depth","","Depth of this mat (it should be the type).",0,null],[12,"channels","","Channels of this mat",0,null],[3,"Point2f","","2D floating points specified by its coordinates `x` and `y`.",null,null],[12,"x","","x coordinate",1,null],[12,"y","","y coordinate",1,null],[3,"Point2i","","2D integer points specified by its coordinates `x` and `y`.",null,null],[12,"x","","x coordinate",2,null],[12,"y","","y coordinate",2,null],[3,"Rect","","The `Rect` defines a rectangle in integer.",null,null],[12,"x","","x coordinate of the left-top corner",3,null],[12,"y","","y coordinate of the left-top corner",3,null],[12,"width","","width of this rectangle",3,null],[12,"height","","height of this rectangle",3,null],[3,"Scalar","","A 4-element struct that is widely used to pass pixel values.",null,null],[3,"Size2f","","`Size2f` struct is used for specifying the size (`width` and `height` as `f32`) of an image or rectangle.",null,null],[12,"width","","width",4,null],[12,"height","","height",4,null],[3,"Size2i","","`Size2i` struct is used for specifying the size (`width` and `height` as `i32`) of an image or rectangle.",null,null],[12,"width","","width",5,null],[12,"height","","height",5,null],[4,"CvType","","Here is the `CvType` in an easy-to-read table.",null,null],[13,"Cv8UC1","","8 bit unsigned (like `uchar`), single channel (grey image)",6,null],[13,"Cv8SC1","","8 bit signed (like `schar`), single channel (grey image)",6,null],[13,"Cv16UC1","","16 bit unsigned (like `ushort`), single channel (grey image)",6,null],[13,"Cv16SC1","","16 bit signed (like `short`), single channel (grey image)",6,null],[13,"Cv32SC1","","32 bit signed (like `int`), single channel (grey image)",6,null],[13,"Cv32FC1","","32 bit float (like `float`), single channel (grey image)",6,null],[13,"Cv64FC1","","32 bit float (like `double`), single channel (grey image)",6,null],[13,"Cv8UC2","","8 bit, two channel (rarelly seen)",6,null],[13,"Cv8UC3","","8 bit unsigned (like `uchar`), three channels (RGB image)",6,null],[13,"Cv8SC3","","8 bit signed (like `schar`), three channels (RGB image)",6,null],[13,"Cv16UC3","","16 bit unsigned (like `ushort`), three channels (RGB image)",6,null],[13,"Cv16SC3","","16 bit signed (like `short`), three channels (RGB image)",6,null],[13,"Cv32SC3","","32 bit signed (like `int`), three channels (RGB image)",6,null],[13,"Cv32FC3","","32 bit float (like `float`), three channels (RGB image)",6,null],[13,"Cv64FC3","","32 bit float (like `double`), three channels (RGB image)",6,null],[4,"FlipCode","","A flag to specify how to flip the image. see Mat::flip",null,null],[13,"XAxis","","Along x-axis: dst[i, j] = src[src.rows - i - 1, j]",7,null],[13,"YAxis","","Along y-axis: dst[i, j] = src[i, src.cols - j - 1]",7,null],[13,"XYAxis","","Along both axis: dst[i, j] = src[src.rows - i - 1, src.cols - j - 1]",7,null],[4,"LineTypes","","Line type",null,null],[13,"Filled","","Default type",8,null],[13,"Line4","","4-connected line",8,null],[13,"Line8","","8-connected line",8,null],[13,"LineAA","","antialiased line",8,null],[4,"NormTypes","","Normalization type. Please refer to OpenCV's documentation.",null,null],[13,"NormInf","","Normalized using `max`",9,null],[13,"NormL1","","Normalized using L1 distance",9,null],[13,"NormL2","","Normalized using L2 distance",9,null],[13,"NormL2Sqr","","Normalized using L2 sqr distance",9,null],[13,"NormHamming","","Normalized using hamming distance",9,null],[13,"NormHamming2","","Normalized using hamming2 distance",9,null],[13,"NormRelative","","Normalized using relative distance",9,null],[13,"NormMinMax","","Normalized using minmax distance",9,null],[11,"fmt","","",0,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"default","","",10,{"inputs":[],"output":{"name":"scalar"}}],[11,"fmt","","",10,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",10,{"inputs":[{"name":"self"}],"output":{"name":"scalar"}}],[11,"new","","Creates a new scalar object.",10,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"all","","Creates a new scalar object with all value being the same.",10,{"inputs":[{"name":"i32"}],"output":{"name":"self"}}],[11,"default","","",2,{"inputs":[],"output":{"name":"point2i"}}],[11,"fmt","","",2,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",2,{"inputs":[{"name":"self"}],"output":{"name":"point2i"}}],[11,"new","","Creats a new `Point2i`.",2,{"inputs":[{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"default","","",1,{"inputs":[],"output":{"name":"point2f"}}],[11,"fmt","","",1,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",1,{"inputs":[{"name":"self"}],"output":{"name":"point2f"}}],[11,"new","","Creats a new `Point2f`.",1,{"inputs":[{"name":"f32"},{"name":"f32"}],"output":{"name":"self"}}],[11,"default","","",5,{"inputs":[],"output":{"name":"size2i"}}],[11,"fmt","","",5,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",5,{"inputs":[{"name":"self"}],"output":{"name":"size2i"}}],[11,"new","","Creates a new `Size2i` object with `width` and `height`",5,{"inputs":[{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"default","","",4,{"inputs":[],"output":{"name":"size2f"}}],[11,"fmt","","",4,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",4,{"inputs":[{"name":"self"}],"output":{"name":"size2f"}}],[11,"default","","",3,{"inputs":[],"output":{"name":"rect"}}],[11,"fmt","","",3,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",3,{"inputs":[{"name":"self"}],"output":{"name":"rect"}}],[11,"eq","","",3,{"inputs":[{"name":"self"},{"name":"rect"}],"output":{"name":"bool"}}],[11,"ne","","",3,{"inputs":[{"name":"self"},{"name":"rect"}],"output":{"name":"bool"}}],[11,"new","","Creates a new `Rect` with (x, y, width, height) parameters.",3,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"scale","","Scales the rectangle by the specified ratio.",3,{"inputs":[{"name":"self"},{"name":"f32"}],"output":{"name":"rect"}}],[11,"normalize_to_mat","","Normalize the rectangle according to the image (if the rectangle is inside the image, then the result should be all within (0, 1).",3,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"rect2f"}}],[11,"fmt","","",8,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",8,{"inputs":[{"name":"self"},{"name":"linetypes"}],"output":{"name":"bool"}}],[11,"clone","","",8,{"inputs":[{"name":"self"}],"output":{"name":"linetypes"}}],[11,"fmt","","",7,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",7,{"inputs":[{"name":"self"}],"output":{"name":"flipcode"}}],[11,"from_raw","","Creates a `Mat` object from raw `CMat` pointer. This will read the rows and cols of the image.",0,null],[11,"new","","Creates an empty `Mat` struct.",0,{"inputs":[],"output":{"name":"mat"}}],[11,"from_buffer","","Creates a new `Mat` from buffer. Note that internally opencv function won't take ownership of the Mat, but when we call `drop`, it will deallocate the memory. To prevent double-freeing, you must `mem::forget` it after use.",0,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"},{"name":"vec"}],"output":{"name":"mat"}}],[11,"with_size","","Create an empty `Mat` with specific size (rows, cols and types).",0,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"zeros","","Create an empty `Mat` with specific size (rows, cols and types).",0,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"}],"output":{"name":"self"}}],[11,"data","","Returns the raw data (as a uchar pointer)",0,null],[11,"total","","Returns the total number of array elements. The method returns the number of array elements (a number of pixels if the array represents an image). For example, images with 1920x1080 resolution will return 2073600.",0,{"inputs":[{"name":"self"}],"output":{"name":"usize"}}],[11,"elem_size","","Returns the matrix element size in bytes.",0,{"inputs":[{"name":"self"}],"output":{"name":"usize"}}],[11,"elem_size1","","Returns the size of each matrix element channel in bytes.",0,{"inputs":[{"name":"self"}],"output":{"name":"usize"}}],[11,"step1","","Returns a normalized step.",0,{"inputs":[{"name":"self"},{"name":"c_int"}],"output":{"name":"usize"}}],[11,"size","","Returns the size of this matrix.",0,{"inputs":[{"name":"self"}],"output":{"name":"size2i"}}],[11,"is_valid","","Check if the `Mat` is valid or not.",0,{"inputs":[{"name":"self"}],"output":{"name":"bool"}}],[11,"roi","","Return a region of interest from a `Mat` specfied by a `Rect`.",0,{"inputs":[{"name":"self"},{"name":"rect"}],"output":{"name":"mat"}}],[11,"logic_and","","Apply a mask to myself.",0,{"inputs":[{"name":"self"},{"name":"mat"}],"output":null}],[11,"flip","","Flips an image around vertical, horizontal, or both axes.",0,{"inputs":[{"name":"self"},{"name":"flipcode"}],"output":null}],[11,"show","","Calls out to highgui to show the image, the duration is specified by `delay`.",0,{"inputs":[{"name":"self"},{"name":"str"},{"name":"i32"}],"output":{"generics":["error"],"name":"result"}}],[11,"cv_type","","Returns the images type. For supported types, please see CvType.",0,{"inputs":[{"name":"self"}],"output":{"generics":["cvtype","error"],"name":"result"}}],[11,"at","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",0,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"t"}}],[11,"at2","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",0,{"inputs":[{"name":"self"},{"name":"i32"},{"name":"i32"}],"output":{"name":"t"}}],[11,"at3","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",0,{"inputs":[{"name":"self"},{"name":"i32"},{"name":"i32"},{"name":"i32"}],"output":{"name":"t"}}],[11,"drop","","",0,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",6,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",6,{"inputs":[{"name":"self"},{"name":"cvtype"}],"output":{"name":"bool"}}],[11,"clone","","",6,{"inputs":[{"name":"self"}],"output":{"name":"cvtype"}}],[11,"from_i64","","",6,{"inputs":[{"name":"i64"}],"output":{"name":"option"}}],[11,"from_u64","","",6,{"inputs":[{"name":"u64"}],"output":{"name":"option"}}],[11,"fmt","","",9,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",9,{"inputs":[{"name":"self"},{"name":"normtypes"}],"output":{"name":"bool"}}],[11,"clone","","",9,{"inputs":[{"name":"self"}],"output":{"name":"normtypes"}}],[11,"from_i64","","",9,{"inputs":[{"name":"i64"}],"output":{"name":"option"}}],[11,"from_u64","","",9,{"inputs":[{"name":"u64"}],"output":{"name":"option"}}],[11,"in_range","","Checks if Mat elements lie between the elements of two other arrays (lowerb and upperb). The output Mat has the same size as `self` and CV_8U type.",0,{"inputs":[{"name":"self"},{"name":"scalar"},{"name":"scalar"}],"output":{"name":"mat"}}],[11,"min_max_loc","","Finds the global minimum and maximum in an array.",0,null],[11,"mix_channels","","Copy specified channels from `self` to the specified channels of output `Mat`.",0,null],[11,"normalize","","Normalize the Mat according to the normalization type.",0,{"inputs":[{"name":"self"},{"name":"f64"},{"name":"f64"},{"name":"normtypes"}],"output":{"name":"mat"}}],[11,"and","","Computes bitwise conjunction between two Mat",0,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"mat"}}],[11,"or","","Computes bitwise disjunction between two Mat",0,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"mat"}}],[11,"xor","","Computes bitwise \"exclusive or\" between two Mat",0,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"mat"}}],[11,"not","","Computes bitwise \"exclusive or\" between two Mat",0,{"inputs":[{"name":"self"}],"output":{"name":"mat"}}],[11,"count_non_zero","","Counts non-zero array elements.",0,{"inputs":[{"name":"self"}],"output":{"name":"i32"}}],[0,"errors","","Errors for OpenCV bindings",null,null],[4,"CvError","cv::errors","",null,null],[13,"InvalidPath","","",11,null],[12,"path","cv::errors::CvError","",11,null],[13,"EnumFromPrimitiveConversionError","cv::errors","",11,null],[12,"value","cv::errors::CvError","",11,null],[11,"fmt","cv::errors","",11,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"cause","","",11,{"inputs":[{"name":"self"}],"output":{"generics":["fail"],"name":"option"}}],[11,"backtrace","","",11,{"inputs":[{"name":"self"}],"output":{"generics":["backtrace"],"name":"option"}}],[11,"fmt","","",11,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[0,"imgproc","cv","Image processing, see OpenCV imgproc.",null,null],[4,"ColorConversionCodes","cv::imgproc","Color conversion code used in cvt_color.",null,null],[13,"BGR2BGRA","","",12,null],[13,"BGRA2BGR","","",12,null],[13,"BGR2RGBA","","",12,null],[13,"RGBA2BGR","","",12,null],[13,"BGR2RGB","","",12,null],[13,"BGRA2RGBA","","",12,null],[13,"BGR2GRAY","","",12,null],[13,"RGB2GRAY","","",12,null],[13,"GRAY2BGR","","",12,null],[13,"GRAY2BGRA","","",12,null],[13,"BGRA2GRAY","","",12,null],[13,"RGBA2GRAY","","",12,null],[13,"BGR2BGR565","","",12,null],[13,"RGB2BGR565","","",12,null],[13,"BGR5652BGR","","",12,null],[13,"BGR5652RGB","","",12,null],[13,"BGRA2BGR565","","",12,null],[13,"RGBA2BGR565","","",12,null],[13,"BGR5652BGRA","","",12,null],[13,"BGR5652RGBA","","",12,null],[13,"GRAY2BGR565","","",12,null],[13,"BGR5652GRAY","","",12,null],[13,"BGR2BGR555","","",12,null],[13,"RGB2BGR555","","",12,null],[13,"BGR5552BGR","","",12,null],[13,"BGR5552RGB","","",12,null],[13,"BGRA2BGR555","","",12,null],[13,"RGBA2BGR555","","",12,null],[13,"BGR5552BGRA","","",12,null],[13,"BGR5552RGBA","","",12,null],[13,"GRAY2BGR555","","",12,null],[13,"BGR5552GRAY","","",12,null],[13,"BGR2XYZ","","",12,null],[13,"RGB2XYZ","","",12,null],[13,"XYZ2BGR","","",12,null],[13,"XYZ2RGB","","",12,null],[13,"BGR2YCrCb","","",12,null],[13,"RGB2YCrCb","","",12,null],[13,"YCrCb2BGR","","",12,null],[13,"YCrCb2RGB","","",12,null],[13,"BGR2HSV","","",12,null],[13,"RGB2HSV","","",12,null],[13,"BGR2Lab","","",12,null],[13,"RGB2Lab","","",12,null],[13,"BGR2Luv","","",12,null],[13,"RGB2Luv","","",12,null],[13,"BGR2HLS","","",12,null],[13,"RGB2HLS","","",12,null],[13,"HSV2BGR","","",12,null],[13,"HSV2RGB","","",12,null],[13,"Lab2BGR","","",12,null],[13,"Lab2RGB","","",12,null],[13,"Luv2BGR","","",12,null],[13,"Luv2RGB","","",12,null],[13,"HLS2BGR","","",12,null],[13,"HLS2RGB","","",12,null],[13,"BGR2HSV_FULL","","",12,null],[13,"RGB2HSV_FULL","","",12,null],[13,"BGR2HLS_FULL","","",12,null],[13,"RGB2HLS_FULL","","",12,null],[13,"HSV2BGR_FULL","","",12,null],[13,"HSV2RGB_FULL","","",12,null],[13,"HLS2BGR_FULL","","",12,null],[13,"HLS2RGB_FULL","","",12,null],[13,"LBGR2Lab","","",12,null],[13,"LRGB2Lab","","",12,null],[13,"LBGR2Luv","","",12,null],[13,"LRGB2Luv","","",12,null],[13,"Lab2LBGR","","",12,null],[13,"Lab2LRGB","","",12,null],[13,"Luv2LBGR","","",12,null],[13,"Luv2LRGB","","",12,null],[13,"BGR2YUV","","",12,null],[13,"RGB2YUV","","",12,null],[13,"YUV2BGR","","",12,null],[13,"YUV2RGB","","",12,null],[13,"YUV2RGB_NV12","","",12,null],[13,"YUV2BGR_NV12","","",12,null],[13,"YUV2RGB_NV21","","",12,null],[13,"YUV2BGR_NV21","","",12,null],[13,"YUV2RGBA_NV12","","",12,null],[13,"YUV2BGRA_NV12","","",12,null],[13,"YUV2RGBA_NV21","","",12,null],[13,"YUV2BGRA_NV21","","",12,null],[13,"YUV2RGB_YV12","","",12,null],[13,"YUV2BGR_YV12","","",12,null],[13,"YUV2RGB_IYUV","","",12,null],[13,"YUV2BGR_IYUV","","",12,null],[13,"YUV2RGBA_YV12","","",12,null],[13,"YUV2BGRA_YV12","","",12,null],[13,"YUV2RGBA_IYUV","","",12,null],[13,"YUV2BGRA_IYUV","","",12,null],[13,"YUV2GRAY_420","","",12,null],[13,"YUV2RGB_UYVY","","",12,null],[13,"YUV2BGR_UYVY","","",12,null],[13,"YUV2RGBA_UYVY","","",12,null],[13,"YUV2BGRA_UYVY","","",12,null],[13,"YUV2RGB_YUY2","","",12,null],[13,"YUV2BGR_YUY2","","",12,null],[13,"YUV2RGB_YVYU","","",12,null],[13,"YUV2BGR_YVYU","","",12,null],[13,"YUV2RGBA_YUY2","","",12,null],[13,"YUV2BGRA_YUY2","","",12,null],[13,"YUV2RGBA_YVYU","","",12,null],[13,"YUV2BGRA_YVYU","","",12,null],[13,"YUV2GRAY_UYVY","","",12,null],[13,"YUV2GRAY_YUY2","","",12,null],[13,"RGBA2mRGBA","","",12,null],[13,"mRGBA2RGBA","","",12,null],[13,"RGB2YUV_I420","","",12,null],[13,"BGR2YUV_I420","","",12,null],[13,"RGBA2YUV_I420","","",12,null],[13,"BGRA2YUV_I420","","",12,null],[13,"RGB2YUV_YV12","","",12,null],[13,"BGR2YUV_YV12","","",12,null],[13,"RGBA2YUV_YV12","","",12,null],[13,"BGRA2YUV_YV12","","",12,null],[13,"BayerBG2BGR","","",12,null],[13,"BayerGB2BGR","","",12,null],[13,"BayerRG2BGR","","",12,null],[13,"BayerGR2BGR","","",12,null],[13,"BayerBG2GRAY","","",12,null],[13,"BayerGB2GRAY","","",12,null],[13,"BayerRG2GRAY","","",12,null],[13,"BayerGR2GRAY","","",12,null],[13,"BayerBG2BGR_VNG","","",12,null],[13,"BayerGB2BGR_VNG","","",12,null],[13,"BayerRG2BGR_VNG","","",12,null],[13,"BayerGR2BGR_VNG","","",12,null],[13,"BayerBG2BGR_EA","","",12,null],[13,"BayerGB2BGR_EA","","",12,null],[13,"BayerRG2BGR_EA","","",12,null],[13,"BayerGR2BGR_EA","","",12,null],[13,"COLORCVT_MAX","","",12,null],[4,"InterpolationFlag","","Interpolation algorithm",null,null],[13,"InterNearst","","nearest neighbor interpolation",13,null],[13,"InterLinear","","bilinear interpolation",13,null],[13,"InterCubic","","bicubic interpolation",13,null],[13,"InterArea","","resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire'-free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.",13,null],[13,"InterLanczos4","","Lanczos interpolation over 8x8 neighborhood",13,null],[13,"InterMax","","mask for interpolation codes",13,null],[13,"WarpFillOutliers","","flag, fills all of the destination image pixels. If some of them correspond to outliers in the source image, they are set to zero",13,null],[13,"WarpInverseMap","","flag, inverse transformation",13,null],[11,"fmt","","",12,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",12,{"inputs":[{"name":"self"},{"name":"colorconversioncodes"}],"output":{"name":"bool"}}],[11,"clone","","",12,{"inputs":[{"name":"self"}],"output":{"name":"colorconversioncodes"}}],[11,"fmt","","",13,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",13,{"inputs":[{"name":"self"},{"name":"interpolationflag"}],"output":{"name":"bool"}}],[11,"clone","","",13,{"inputs":[{"name":"self"}],"output":{"name":"interpolationflag"}}],[11,"line","cv","Draws a simple line.",0,{"inputs":[{"name":"self"},{"name":"point2i"},{"name":"point2i"}],"output":null}],[11,"line_custom","","Draws a line with custom color, thickness and linetype.",0,{"inputs":[{"name":"self"},{"name":"point2i"},{"name":"point2i"},{"name":"scalar"},{"name":"i32"},{"name":"linetypes"},{"name":"i32"}],"output":null}],[11,"rectangle","","Draws a simple, thick, or filled up-right rectangle.",0,{"inputs":[{"name":"self"},{"name":"rect"}],"output":null}],[11,"rectangle_custom","","Draws a rectangle with custom color, thickness and linetype.",0,{"inputs":[{"name":"self"},{"name":"rect"},{"name":"scalar"},{"name":"i32"},{"name":"linetypes"}],"output":null}],[11,"rectangle2f","","Draw a simple, thick, or filled up-right rectangle.",0,{"inputs":[{"name":"self"},{"name":"rect2f"}],"output":null}],[11,"ellipse","","Draws a simple, thick ellipse",0,{"inputs":[{"name":"self"},{"name":"point2i"},{"name":"size2i"},{"name":"f64"},{"name":"f64"},{"name":"f64"}],"output":null}],[11,"ellipse_custom","","Draws a custom ellipse",0,{"inputs":[{"name":"self"},{"name":"point2i"},{"name":"size2i"},{"name":"f64"},{"name":"f64"},{"name":"f64"},{"name":"scalar"},{"name":"i32"},{"name":"linetypes"},{"name":"i32"}],"output":null}],[11,"cvt_color","","Convert an image from one color space to another.",0,{"inputs":[{"name":"self"},{"name":"colorconversioncodes"}],"output":{"name":"mat"}}],[11,"pyr_down","","Blurs an image and downsamples it. This function performs the downsampling step of the Gaussian pyramid construction.",0,{"inputs":[{"name":"self"}],"output":{"name":"mat"}}],[11,"resize_to","","Resizes an image.",0,{"inputs":[{"name":"self"},{"name":"size2i"},{"name":"interpolationflag"}],"output":{"name":"mat"}}],[11,"resize_by","","Resizes an image.",0,{"inputs":[{"name":"self"},{"name":"f64"},{"name":"f64"},{"name":"interpolationflag"}],"output":{"name":"mat"}}],[11,"calc_hist","","Calculate a histogram of an image.",0,null],[11,"calc_back_project","","Calculate the back projection of a histogram. The function calculates the back project of the histogram.",0,null],[0,"imgcodecs","","Image file reading and writing, see OpenCV imgcodecs.",null,null],[4,"ImreadModes","cv::imgcodecs","ImreadModes",null,null],[13,"ImreadUnchanged","","If set, return the loaded image as is (with alpha channel, otherwise it gets cropped",14,null],[13,"ImreadGrayscale","","If set, always convert image to the single channel grayscale image.",14,null],[13,"ImreadColor","","If set, always convert image to the 3 channel BGR color image.",14,null],[13,"ImreadAnydepth","","If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.",14,null],[13,"ImreadAnycolor","","If set, the image is read in any possible color format.",14,null],[13,"ImreadLoadGdal","","If set, use the gdal driver for loading the image.",14,null],[13,"ImreadReducedGrayscale2","","If set, always convert image to the single channel grayscale image and the image size reduced 1/2.",14,null],[13,"ImreadReducedColor2","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/2.",14,null],[13,"ImreadReducedGrayscale4","","If set, always convert image to the single channel grayscale image and the image size reduced 1/4.",14,null],[13,"ImreadReducedColor4","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/4.",14,null],[13,"ImreadReducedGrayscale8","","If set, always convert image to the single channel grayscale image and the image size reduced 1/8.",14,null],[13,"ImreadReducedColor8","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/8.",14,null],[4,"ImwriteFlags","","Imwrite flags",null,null],[13,"ImwriteJpegQuality","","For JPEG, it can be a quality from 0 to 100 (the higher is the better). Default value is 95.",15,null],[13,"ImwriteJpegProgressive","","Enable JPEG features, 0 or 1, default is False.",15,null],[13,"ImwriteJpegOptimize","","Enable JPEG features, 0 or 1, default is False.",15,null],[13,"ImwriteJpegRstInterval","","JPEG restart interval, 0 - 65535, default is 0 - no restart.",15,null],[13,"ImwriteJpegLumaQuality","","Separate luma quality level, 0 - 100, default is 0 - don't use.",15,null],[13,"ImwriteJpegChromaQuality","","Separate chroma quality level, 0 - 100, default is 0 - don't use.",15,null],[13,"ImwritePngCompression","","For PNG, it can be the compression level from 0 to 9. A higher value means a smaller size and longer compression time. Default value is 3. Also strategy is changed to IMWRITE_PNG_STRATEGY_DEFAULT (Z_DEFAULT_STRATEGY).",15,null],[13,"ImwritePngStrategy","","One of cv::ImwritePNGFlags, default is IMWRITE_PNG_STRATEGY_DEFAULT.",15,null],[13,"ImwritePngBilevel","","Binary level PNG, 0 or 1, default is 0.",15,null],[13,"ImwritePxmBinary","","For PPM, PGM, or PBM, it can be a binary format flag, 0 or 1. Default value is 1.",15,null],[13,"ImwriteWebpQuality","","For WEBP, it can be a quality from 1 to 100 (the higher is the better). By default (without any parameter) and for quality above 100 the lossless compression is used.",15,null],[13,"ImwritePamTupletype","","For PAM, sets the TUPLETYPE field to the corresponding string value that is defined for the format",15,null],[4,"ImwritePngFlags","","Imwrite PNG flag",null,null],[13,"ImwritePngStrategyDefault","","Use this value for normal data.",16,null],[13,"ImwritePngStrategyFiltered","","Use this value for data produced by a filter (or predictor).Filtered data consists mostly of small values with a somewhat random distribution. In this case, the compression algorithm is tuned to compress them better.",16,null],[13,"ImwritePngStrategyHuffmanOnly","","Use this value to force Huffman encoding only (no string match).",16,null],[13,"ImwritePngStrategyRle","","Use this value to limit match distances to one (run-length encoding).",16,null],[13,"ImwritePngStrategyFixed","","Using this value prevents the use of dynamic Huffman codes, allowing for a simpler decoder for special applications.",16,null],[11,"fmt","","",14,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",14,{"inputs":[{"name":"self"},{"name":"imreadmodes"}],"output":{"name":"bool"}}],[11,"clone","","",14,{"inputs":[{"name":"self"}],"output":{"name":"imreadmodes"}}],[11,"fmt","","",15,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",15,{"inputs":[{"name":"self"},{"name":"imwriteflags"}],"output":{"name":"bool"}}],[11,"clone","","",15,{"inputs":[{"name":"self"}],"output":{"name":"imwriteflags"}}],[11,"fmt","","",16,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"eq","","",16,{"inputs":[{"name":"self"},{"name":"imwritepngflags"}],"output":{"name":"bool"}}],[11,"clone","","",16,{"inputs":[{"name":"self"}],"output":{"name":"imwritepngflags"}}],[11,"from_path","cv","Creates a `Mat` from reading the image specified by the path.",0,{"inputs":[{"name":"p"},{"name":"imreadmodes"}],"output":{"generics":["mat"],"name":"option"}}],[11,"imdecode","","Decodes an image from `buf` according to the specified mode.",0,null],[11,"imencode","","Encodes an image; the encoding scheme depends on the extension provided; additional write flags can be passed in using a vector. If successful, returns an owned vector of the encoded image.",0,{"inputs":[{"name":"self"},{"name":"str"},{"generics":["imwriteflags"],"name":"vec"}],"output":{"generics":["vec"],"name":"option"}}],[0,"videoio","","Media I/O, see OpenCV videoio",null,null],[3,"VideoCapture","cv::videoio","Video capturing from video files, image sequences or cameras.",null,null],[3,"VideoWriter","","`VideoWriter` provides easy access to write videos to files. - On Linux FFMPEG is used to write videos; - On Windows FFMPEG or VFW is used; - On MacOSX QTKit is used.",null,null],[4,"CapProp","","Video capture's property identifier.",null,null],[13,"PosMsec","","Current position of the video file in milliseconds or video capture timestamp.",17,null],[13,"PosFrames","","0-based index of the frame to be decoded/captured next.",17,null],[13,"PosAviRatio","","Relative position of the video file: 0 - start of the film, 1 - end of the film.",17,null],[13,"FrameWidth","","Width of the frames in the video stream.",17,null],[13,"FrameHeight","","Height of the frames in the video stream.",17,null],[13,"Fps","","Frame rate.",17,null],[13,"Fourcc","","4-character code of codec.",17,null],[13,"FrameCount","","Number of frames in the video file.",17,null],[13,"Format","","Format of the Mat objects returned by retrieve() .",17,null],[13,"Mode","","Backend-specific value indicating the current capture mode.",17,null],[13,"Brightness","","Brightness of the image (only for cameras).",17,null],[13,"Contrast","","Contrast of the image (only for cameras).",17,null],[13,"Saturation","","Saturation of the image (only for cameras).",17,null],[13,"Hue","","Hue of the image (only for cameras).",17,null],[13,"Gain","","Gain of the image (only for cameras).",17,null],[13,"Exposure","","Exposure (only for cameras).",17,null],[13,"ConvertRgb","","Boolean flags indicating whether images should be converted to RGB.",17,null],[13,"WhiteBalanceBlueU","","Currently not supported",17,null],[13,"Rectification","","Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)",17,null],[13,"Monochrome","","",17,null],[13,"Sharpness","","",17,null],[13,"AutoExposure","","",17,null],[13,"Gamma","","",17,null],[13,"Temperature","","",17,null],[13,"Trigger","","",17,null],[13,"TriggerDelay","","",17,null],[13,"WhiteBalanceRedV","","",17,null],[13,"Zoom","","",17,null],[13,"Focus","","",17,null],[13,"Guid","","",17,null],[13,"IsoSpeed","","",17,null],[13,"Backlight","","",17,null],[13,"Pan","","",17,null],[13,"Tilt","","",17,null],[13,"Roll","","",17,null],[13,"Iris","","",17,null],[13,"Settings","","",17,null],[13,"Buffersize","","",17,null],[13,"Autofocus","","",17,null],[4,"VideoWriterProperty","","`VideoWriter`'s property identifier.",null,null],[13,"Quality","","Current quality of the encoded videostream.",18,null],[13,"FrameBytes","","(Read-only) Size of just encoded video frame; note that the encoding order may be different from representation order.",18,null],[13,"NStripes","","Number of stripes for parallel encoding",18,null],[5,"fourcc","","Converts from four character code to `i32` for OpenCV.",null,{"inputs":[{"name":"char"},{"name":"char"},{"name":"char"},{"name":"char"}],"output":{"name":"i32"}}],[5,"codec_name","","Converts from OpenCV's int to four character code.",null,{"inputs":[{"name":"i32"}],"output":{"generics":["string"],"name":"option"}}],[11,"fmt","","",19,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",17,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",17,{"inputs":[{"name":"self"}],"output":{"name":"capprop"}}],[11,"eq","","",17,{"inputs":[{"name":"self"},{"name":"capprop"}],"output":{"name":"bool"}}],[11,"hash","","",17,null],[11,"new","","Creates a capture device with specified camera id. If there is a single camera connected, just pass 0.",19,{"inputs":[{"name":"i32"}],"output":{"name":"self"}}],[11,"from_path","","Creates a capture device with the path of a video file (eg. video.avi). This also supports image sequence, eg. img_%02d.jpg, which will read samples like img_00.jpg, img_01.jpg, img_02.jpg, ...).",19,{"inputs":[{"name":"str"}],"output":{"name":"self"}}],[11,"is_open","","Returns true if video capturing has been initialized already.",19,{"inputs":[{"name":"self"}],"output":{"name":"bool"}}],[11,"read","","Grabs, decodes and returns the next video frame. `read` combines `VideoCapture::grab` and `VideoCapture::retrieve` in one call. This is the most convenient method for reading video files or capturing data from decode and return the just grabbed frame.",19,{"inputs":[{"name":"self"}],"output":{"generics":["mat"],"name":"option"}}],[11,"set","","Sets a property in the `VideoCapture`.",19,{"inputs":[{"name":"self"},{"name":"capprop"},{"name":"f64"}],"output":{"name":"bool"}}],[11,"get","","Gets a property in the `VideoCapture`.",19,{"inputs":[{"name":"self"},{"name":"capprop"}],"output":{"generics":["f64"],"name":"option"}}],[11,"drop","","",19,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",20,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"new","","`VideoWriter` constructor. * path – Name of the output video file. * fourcc – 4-character code of codec used to compress the frames. For   example, VideoWriter::fourcc('P','I','M','1') is a MPEG-1 codec,   VideoWriter::fourcc('M','J','P','G') is a motion-jpeg codec etc. List   of codes can be obtained at Video Codecs by FOURCC page. * fps – Framerate of the created video stream. * frame_size – Size of the video frames. * is_color – If it is not zero, the encoder will expect and encode color   frames, otherwise it will work with grayscale frames (the flag is   currently supported on Windows only).",20,{"inputs":[{"name":"str"},{"name":"i32"},{"name":"f64"},{"name":"size2i"},{"name":"bool"}],"output":{"name":"videowriter"}}],[11,"open","","`VideoWriter` constructor. * path – Name of the output video file. * fourcc – 4-character code of codec used to compress the frames. For   example, VideoWriter::fourcc('P','I','M','1') is a MPEG-1 codec,   VideoWriter::fourcc('M','J','P','G') is a motion-jpeg codec etc. List   of codes can be obtained at Video Codecs by FOURCC page. * fps – Framerate of the created video stream. * frame_size – Size of the video frames. * is_color – If it is not zero, the encoder will expect and encode color   frames, otherwise it will work with grayscale frames (the flag is   currently supported on Windows only).",20,{"inputs":[{"name":"self"},{"name":"str"},{"name":"i32"},{"name":"f64"},{"name":"size2i"},{"name":"bool"}],"output":{"name":"bool"}}],[11,"write","","Writes the specified image to video file. It must have the same size as has been specified when opening the video writer.",20,{"inputs":[{"name":"self"},{"name":"mat"}],"output":null}],[11,"is_open","","Returns true if video writer has been initialized already.",20,{"inputs":[{"name":"self"}],"output":{"name":"bool"}}],[11,"set","","Sets a property in the `VideoWriter`. Note: `VideoWriterProperty::FrameBytes` is read-only.",20,{"inputs":[{"name":"self"},{"name":"videowriterproperty"},{"name":"f64"}],"output":{"name":"bool"}}],[11,"get","","Gets a property in the `VideoWriter`.",20,{"inputs":[{"name":"self"},{"name":"videowriterproperty"}],"output":{"generics":["f64"],"name":"option"}}],[11,"default","","",20,{"inputs":[],"output":{"name":"videowriter"}}],[11,"drop","","",20,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",18,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",18,{"inputs":[{"name":"self"}],"output":{"name":"videowriterproperty"}}],[11,"eq","","",18,{"inputs":[{"name":"self"},{"name":"videowriterproperty"}],"output":{"name":"bool"}}],[11,"hash","","",18,null],[0,"highgui","cv","highgui: high-level GUI",null,null],[4,"WindowFlags","cv::highgui","Flags for highgui_named_window. This only supports a subset of all cv::WindowFlags because C/C++ allows enum with the same value but Rust is stricter.",null,null],[13,"WindowNormal","","the window can be resized (no constraint) or switched to fullscreen.",21,null],[13,"WindowAutosize","","the window is constrained by the image displayed.",21,null],[13,"WindowOpengl","","the window is with opengl support.",21,null],[13,"WindowFreeRatio","","the window can be resized arbitrarily (no ratio constraint).",21,null],[4,"MouseEventTypes","","Mouse Events",null,null],[13,"MouseMove","","Indicates that the mouse has moved over the window.",22,null],[13,"LButtonDown","","Indicates that the left mouse button is pressed.",22,null],[13,"RButtonDown","","Indicates that the right mouse button is pressed.",22,null],[13,"MButtonDown","","Indicates that the middle mouse button is pressed.",22,null],[13,"LButtonUp","","Indicates that left mouse button is released.",22,null],[13,"RButtonUp","","Indicates that right mouse button is released.",22,null],[13,"MButtonUp","","Indicates that middle mouse button is released.",22,null],[13,"LButtonClick","","Indicates that left mouse button is double clicked.",22,null],[13,"RButtonClick","","Indicates that right mouse button is double clicked.",22,null],[13,"MButtonClick","","Indicates that middle mouse button is double clicked.",22,null],[13,"MouseWheel","","Positive/negative means forward/backward scrolling.",22,null],[13,"MouseHWheel","","Positive/negative means right and left scrolling.",22,null],[5,"highgui_named_window","","Create a window that can be used as a placeholder for images and trackbars. All created windows are referred to by their names. If a window with the same name already exists, the function does nothing.",null,{"inputs":[{"name":"str"},{"name":"windowflags"}],"output":null}],[5,"highgui_destroy_window","","Destroy the specified window with the given name.",null,{"inputs":[{"name":"str"}],"output":null}],[5,"highgui_set_mouse_callback","","Set mouse handler for the specified window (identified by name). A callback handler should be provided and optional user_data can be passed around.",null,null],[6,"MouseCallbackData","","Pointer referring to the data used in MouseCallback",null,null],[6,"MouseCallback","","Callback function for mouse events, primarily used in highgui_set_mouse_callback",null,null],[11,"clone","","",21,{"inputs":[{"name":"self"}],"output":{"name":"windowflags"}}],[11,"fmt","","",21,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",22,{"inputs":[{"name":"self"}],"output":{"name":"mouseeventtypes"}}],[11,"fmt","","",22,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[0,"video","cv","Video Analysis, see OpenCV video",null,null],[0,"tracking","cv::video","Object Tracking, see OpenCV video track",null,null],[3,"TermCriteria","cv::video::tracking","Termination criteria for iterative algorithms.",null,null],[4,"TermType","","Term criteria type, can be one of: Count, Eps or Count + Eps",null,null],[13,"Count","","The maximum number of iterations or elements to compute",23,null],[13,"EPS","","the desired accuracy or change in parameters at which the iterative algorithm stops.",23,null],[11,"clone","","",23,{"inputs":[{"name":"self"}],"output":{"name":"termtype"}}],[11,"fmt","","",23,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",24,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"new","","Creates a new termination criteria.",24,{"inputs":[{"name":"termtype"},{"name":"i32"},{"name":"f64"}],"output":{"name":"self"}}],[11,"drop","","",24,{"inputs":[{"name":"self"}],"output":null}],[11,"camshift","cv","Finds an object center, size, and orientation; returns as `RotatedRect`.",0,{"inputs":[{"name":"self"},{"name":"rect"},{"name":"termcriteria"}],"output":{"name":"rotatedrect"}}],[0,"analysis","cv::video","Motion Analysis, see OpenCV video motion",null,null],[0,"objdetect","cv","Various object detection algorithms, such as Haar feature-based cascade classifier for object detection and histogram of oriented gradients (HOG).",null,null],[3,"CascadeClassifier","cv::objdetect","Cascade classifier class for object detection.",null,null],[3,"SvmDetector","","SvmDetector",null,null],[12,"inner","","Pointer to the inner data structure",25,null],[3,"HogParams","","Parameters that controls the behavior of HOG.",null,null],[12,"win_size","","Detection window size. Align to block size and block stride. The default is 64x128, trained the same as original paper.",26,null],[12,"block_size","","Block size in pixels. Align to cell size. Only (16,16) is supported for now (at least for GPU).",26,null],[12,"block_stride","","Block stride. It must be a multiple of cell size.",26,null],[12,"cell_size","","Cell size. Only (8, 8) is supported for now.",26,null],[12,"nbins","","Number of bins. Only 9 bins per cell are supported for now.",26,null],[12,"win_sigma","","Gaussian smoothing window parameter. Default -1 for CPU and 4.0 for GPU.",26,null],[12,"l2hys_threshold","","L2-Hys normalization method shrinkage. Default 0.2.",26,null],[12,"gamma_correction","","Flag to specify whether the gamma correction preprocessing is required or not. Default false.",26,null],[12,"nlevels","","Maximum number of detection window increases (HOG scales). Default: 64.",26,null],[12,"hit_threshold","","Threshold for the distance between features and SVM classifying plane. Usually it is 0 and should be specfied in the detector coefficients (as the last free coefficient). But if the free coefficient is omitted (which is allowed), you can specify it manually here.",26,null],[12,"win_stride","","Window stride. It must be a multiple of block stride.",26,null],[12,"padding","","Padding",26,null],[12,"scale","","Coefficient of the detection window increase.",26,null],[12,"group_threshold","","Coefficient to regulate the similarity threshold. When detected, some objects can be covered by many rectangles. 0 means not to perform grouping.",26,null],[12,"use_meanshift_grouping","","The useMeanShiftGrouping parameter is a boolean indicating whether or not mean-shift grouping should be performed to handle potential overlapping bounding boxes. While this value should not be set and users should employ non-maxima suppression instead, we support setting it as a library function.",26,null],[12,"final_threshold","","The `finalThreshold` parameter is mainly used to select the clusters that have at least `finalThreshold + 1` rectangles. This parameter is passed when meanShift is enabled; the function rejects the small clusters containing less than or equal to `finalThreshold` rectangles, computes the average rectangle size for the rest of the accepted clusters and adds those to the output rectangle list.",26,null],[3,"HogDescriptor","","`HogDescriptor` implements Histogram of Oriented Gradients.",null,null],[12,"params","","Hog parameters.",27,null],[4,"CSvmDetector","","Opaque type for C/C++ SvmDetector object",null,null],[8,"ObjectDetect","","An object detect trait.",null,null],[10,"detect","","Detects the object inside this image and returns a list of detections with their confidence.",28,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"vec"}}],[11,"fmt","","",29,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"detect","","",29,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"vec"}}],[11,"new","","Creates a cascade classifier, uninitialized. Before use, call load.",29,{"inputs":[],"output":{"name":"cascadeclassifier"}}],[11,"from_path","","Creates a cascade classifier using the model specified.",29,{"inputs":[{"name":"p"}],"output":{"generics":["error"],"name":"result"}}],[11,"load","","Loads the classifier model from a path.",29,{"inputs":[{"name":"self"},{"name":"p"}],"output":{"generics":["error"],"name":"result"}}],[11,"detect_multiscale","","The default detection uses scale factor 1.1, minNeighbors 3, no min size or max size.",29,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"generics":["rect"],"name":"vec"}}],[11,"detect_with_params","","Detects the object using parameters specified.",29,{"inputs":[{"name":"self"},{"name":"mat"},{"name":"f32"},{"name":"i32"},{"name":"size2i"},{"name":"size2i"}],"output":{"generics":["rect"],"name":"vec"}}],[11,"drop","","",29,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",30,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",30,{"inputs":[{"name":"self"}],"output":{"name":"csvmdetector"}}],[11,"fmt","","",25,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"default_people_detector","","The built-in people detector.",25,{"inputs":[],"output":{"name":"svmdetector"}}],[11,"daimler_people_detector","","Returns the Daimler people detector.",25,{"inputs":[],"output":{"name":"svmdetector"}}],[11,"drop","","",25,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",26,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",26,{"inputs":[{"name":"self"}],"output":{"name":"hogparams"}}],[11,"default","","",26,{"inputs":[],"output":{"name":"hogparams"}}],[11,"fmt","","",27,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"default","","",27,{"inputs":[],"output":{"name":"hogdescriptor"}}],[11,"detect","","",27,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"vec"}}],[11,"with_params","","Creates a HogDescriptor with provided parameters.",27,{"inputs":[{"name":"hogparams"}],"output":{"name":"hogdescriptor"}}],[11,"set_svm_detector","","Sets the SVM detector.",27,{"inputs":[{"name":"self"},{"name":"svmdetector"}],"output":null}],[11,"drop","","",27,{"inputs":[{"name":"self"}],"output":null}],[0,"features2d","cv","Provide the type that encapsulates all the parameters of the MSER extraction algorithm",null,null],[3,"MSER","cv::features2d","Maximally stable extremal region extractor.",null,null],[3,"MSERBuilder","","Builder that provides defaults for MSER",null,null],[11,"fmt","","",31,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"new","","Creates a new maximally stable extremal region extractor criteria.",31,{"inputs":[{"name":"i32"},{"name":"i32"},{"name":"i32"},{"name":"f64"},{"name":"f64"},{"name":"i32"},{"name":"f64"},{"name":"f64"},{"name":"i32"}],"output":{"name":"self"}}],[11,"detect_regions","","Detect MSER regions.",31,null],[11,"drop","","",31,{"inputs":[{"name":"self"}],"output":null}],[11,"fmt","","",32,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"clone","","",32,{"inputs":[{"name":"self"}],"output":{"name":"mserbuilder"}}],[11,"default","","",32,{"inputs":[],"output":{"name":"mserbuilder"}}],[11,"delta","","Replace current delta with specified value",32,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"self"}}],[11,"min_area","","Replace current min_area with specified value",32,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"self"}}],[11,"max_area","","Replace current max_area with specified value",32,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"self"}}],[11,"max_variation","","Replace current max_variation with specified value",32,{"inputs":[{"name":"self"},{"name":"f64"}],"output":{"name":"self"}}],[11,"min_diversity","","Replace current min_diversity with specified value",32,{"inputs":[{"name":"self"},{"name":"f64"}],"output":{"name":"self"}}],[11,"max_evolution","","Replace current max_evolution with specified value",32,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"self"}}],[11,"area_threshold","","Replace current area_threshold with specified value",32,{"inputs":[{"name":"self"},{"name":"f64"}],"output":{"name":"self"}}],[11,"min_margin","","Replace current min_margin with specified value",32,{"inputs":[{"name":"self"},{"name":"f64"}],"output":{"name":"self"}}],[11,"edge_blur_size","","Replace current edge_blur_size with specified value",32,{"inputs":[{"name":"self"},{"name":"i32"}],"output":{"name":"self"}}],[11,"into","","",32,{"inputs":[{"name":"self"}],"output":{"name":"mser"}}],[0,"cuda","cv","Bindings to OpenCV's classes and functions that exploits GPU/Cuda. See cv::cuda",null,null],[3,"GpuMat","cv::cuda","`GpuMat` data structure in rust, bound to an opaque type in C/C++.",null,null],[12,"inner","","The pointer to the opaque C/C++ data structure",33,null],[12,"cols","","Number of columns",33,null],[12,"rows","","Number of rows",33,null],[12,"depth","","Depth of this mat",33,null],[3,"GpuHog","","Data structure that performs Histogram of Gradient (HOG).",null,null],[12,"params","","Hog parameters.",34,null],[12,"return_score","","Should return detection scores",34,null],[3,"GpuCascade","","Data structure that performs object detection with a cascade classifier.",null,null],[4,"CGpuMat","","Opaque data struct for C/C++ cv::cuda::GpuMat bindings",null,null],[4,"CGpuHog","","Opaque data struct for C bindings",null,null],[4,"CGpuCascade","","Opaque data struct for C bindings",null,null],[11,"clone","","",35,{"inputs":[{"name":"self"}],"output":{"name":"cgpumat"}}],[11,"fmt","","",35,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",33,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"default","","Creates a default `GpuMat`.",33,{"inputs":[],"output":{"name":"gpumat"}}],[11,"from_raw","","Creates a `GpuMat` from raw pointer.",33,null],[11,"upload","","Uploads a normal `Mat`",33,{"inputs":[{"name":"self"},{"name":"mat"}],"output":null}],[11,"drop","","",33,{"inputs":[{"name":"self"}],"output":null}],[11,"from","cv","",0,{"inputs":[{"name":"gpumat"}],"output":{"name":"mat"}}],[11,"from","cv::cuda","",33,{"inputs":[{"name":"mat"}],"output":{"name":"gpumat"}}],[11,"clone","","",36,{"inputs":[{"name":"self"}],"output":{"name":"cgpuhog"}}],[11,"fmt","","",36,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",34,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"detect","","",34,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"vec"}}],[11,"default","","",34,{"inputs":[],"output":{"name":"gpuhog"}}],[11,"new","","Creates a new GpuHog detector.",34,{"inputs":[{"name":"size2i"},{"name":"size2i"},{"name":"size2i"},{"name":"size2i"},{"name":"i32"}],"output":{"name":"gpuhog"}}],[11,"return_score","","Should or not return the detection score",34,{"inputs":[{"name":"self"},{"name":"bool"}],"output":null}],[11,"with_params","","Creates a new GpuHog detector with parameters specified inside `params`.",34,{"inputs":[{"name":"hogparams"}],"output":{"name":"gpuhog"}}],[11,"set_svm_detector","","Sets the SVM detector.",34,{"inputs":[{"name":"self"},{"name":"svmdetector"}],"output":null}],[11,"drop","","",34,{"inputs":[{"name":"self"}],"output":null}],[11,"clone","","",37,{"inputs":[{"name":"self"}],"output":{"name":"cgpucascade"}}],[11,"fmt","","",37,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"fmt","","",38,{"inputs":[{"name":"self"},{"name":"formatter"}],"output":{"name":"result"}}],[11,"from_path","","Loads the classifier from a file.",38,{"inputs":[{"name":"p"}],"output":{"generics":["error"],"name":"result"}}],[11,"detect_multiscale","","Detects objects of different sizes in the input image.",38,{"inputs":[{"name":"self"},{"name":"gpumat"}],"output":{"generics":["rect"],"name":"vec"}}],[11,"set_find_largest_object","","Sets whether or not to find the only largest object.",38,{"inputs":[{"name":"self"},{"name":"bool"}],"output":null}],[11,"set_max_num_objects","","Sets the maximum number of objects.",38,{"inputs":[{"name":"self"},{"name":"i32"}],"output":null}],[11,"set_min_neighbors","","Sets minimal neighbors required for a detection to be valid.",38,{"inputs":[{"name":"self"},{"name":"i32"}],"output":null}],[11,"set_max_object_size","","Sets the maximun object size.",38,{"inputs":[{"name":"self"},{"name":"size2i"}],"output":null}],[11,"set_min_object_size","","Sets the minimal object size.",38,{"inputs":[{"name":"self"},{"name":"size2i"}],"output":null}],[11,"set_scale_factor","","Sets the scale factor used in multiscale detection.",38,{"inputs":[{"name":"self"},{"name":"f64"}],"output":null}],[11,"get_classifier_size","","Returns the classifier size.",38,{"inputs":[{"name":"self"}],"output":{"name":"size2i"}}],[11,"get_find_largest_object_flag","","Returns if the CascadeClassifier will only return the largest object.",38,{"inputs":[{"name":"self"}],"output":{"name":"bool"}}],[11,"get_max_num_objects","","Returns the allowed maximal number of detected objects.",38,{"inputs":[{"name":"self"}],"output":{"name":"i32"}}],[11,"get_min_neighbors","","Returns the number of minimal neighbors required for a detection to be valid.",38,{"inputs":[{"name":"self"}],"output":{"name":"i32"}}],[11,"get_max_object_size","","Returns the maximum object size.",38,{"inputs":[{"name":"self"}],"output":{"name":"size2i"}}],[11,"get_min_object_size","","Returns the minimal object size.",38,{"inputs":[{"name":"self"}],"output":{"name":"size2i"}}],[11,"get_scale_factor","","Returns the scale factor.",38,{"inputs":[{"name":"self"}],"output":{"name":"f64"}}],[11,"detect","","",38,{"inputs":[{"name":"self"},{"name":"mat"}],"output":{"name":"vec"}}],[11,"drop","","",38,{"inputs":[{"name":"self"}],"output":null}]],"paths":[[3,"Mat"],[3,"Point2f"],[3,"Point2i"],[3,"Rect"],[3,"Size2f"],[3,"Size2i"],[4,"CvType"],[4,"FlipCode"],[4,"LineTypes"],[4,"NormTypes"],[3,"Scalar"],[4,"CvError"],[4,"ColorConversionCodes"],[4,"InterpolationFlag"],[4,"ImreadModes"],[4,"ImwriteFlags"],[4,"ImwritePngFlags"],[4,"CapProp"],[4,"VideoWriterProperty"],[3,"VideoCapture"],[3,"VideoWriter"],[4,"WindowFlags"],[4,"MouseEventTypes"],[4,"TermType"],[3,"TermCriteria"],[3,"SvmDetector"],[3,"HogParams"],[3,"HogDescriptor"],[8,"ObjectDetect"],[3,"CascadeClassifier"],[4,"CSvmDetector"],[3,"MSER"],[3,"MSERBuilder"],[3,"GpuMat"],[3,"GpuHog"],[4,"CGpuMat"],[4,"CGpuHog"],[4,"CGpuCascade"],[3,"GpuCascade"]]};
initSearch(searchIndex);
